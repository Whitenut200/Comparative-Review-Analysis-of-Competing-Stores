from urllib.parse import quote
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
import time, pandas as pd
from pathlib import Path

# '방학역 삼겹살' 검색 결과에서 이름만 중복 제거해 TOP8 추출 + CSV 저장
# 경쟁가게 이름 추출하기

QUERY = "방학역 삼겹살"

# 1) 검색 페이지 열고 searchIframe 진입
driver.switch_to.default_content()
driver.get(f"https://map.naver.com/p/search/{quote(QUERY)}")
wait.until(EC.frame_to_be_available_and_switch_to_it((By.CSS_SELECTOR, "iframe#searchIframe")))
print("@ searchIframe 진입")

# 2) 결과 끝까지 스크롤(더 로드될 게 없을 때까지)
stable = 0
prev_h = 0
while stable < 3:
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    time.sleep(0.8)
    h = driver.execute_script("return document.body.scrollHeight;")
    if h == prev_h:
        stable += 1
    else:
        stable = 0
    prev_h = h
print("@ 스크롤 완료")

# 3) 이름만 수집 (우선: span.TYaxT → 폴백: place_bluelink 내부 텍스트)
name_els = driver.find_elements(By.CSS_SELECTOR, "span.TYaxT")
if not name_els:
    # 폴백: 상호 링크 내부 첫 span 텍스트
    name_els = driver.find_elements(By.XPATH, "//a[contains(@href,'/entry/place/')]/span[normalize-space()]")

raw_names = [(e.text or "").strip() for e in name_els]
raw_names = [n for n in raw_names if n]  # 빈 값 제거

# 4) 중복 제거(등장 순서 보존) 후 TOP8 (광고로 인해 중복되는 것을 방지)
seen = set()
names = []
for n in raw_names:
    if n not in seen:
        seen.add(n)
        names.append(n)
    if len(names) >= 8:
        break

print("@ 추출된 상호명(Top 8, dedup):")
for i, n in enumerate(names, 1):
    print(f"{i}. {n}")

# 5) CSV 저장
outdir = Path.cwd() / "output"
outdir.mkdir(exist_ok=True)
outpath = outdir / "competitors_top8_names.csv"
pd.DataFrame({"rank": range(1, len(names)+1), "name": names}).to_csv(outpath, index=False, encoding="utf-8-sig")
print("@ 저장:", outpath)
